{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12ac4322",
   "metadata": {},
   "source": [
    "\n",
    "# Sales Data Analysis and Prediction\n",
    "\n",
    "This Jupyter notebook explores a synthetic sales dataset generated for practicing data analysis and predictive modeling skills. The dataset simulates sales transactions across various product categories, regions, customer demographics, and time periods. The analysis includes exploratory data analysis (EDA), visualizations, and building predictive models for both regression and classification tasks.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Understand the structure of the synthetic sales dataset.\n",
    "- Perform exploratory data analysis to uncover insights about sales patterns, customer demographics, and regional performance.\n",
    "- Visualize relationships between variables using charts and plots.\n",
    "- Build a regression model to predict **Total_Sales** based on available features.\n",
    "- Build a classification model to predict whether **Sales_Quantity** is above the median.\n",
    "- Evaluate model performance using appropriate metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bbe63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Visualization settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'synthetic_sales_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summary statistics\n",
    "data.describe(include='all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec18703",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution of Total_Sales\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(data['Total_Sales'], bins=30, kde=True)\n",
    "plt.title('Distribution of Total Sales')\n",
    "plt.xlabel('Total Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Sales quantity by product category\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x='Product_Category', y='Sales_Quantity', data=data)\n",
    "plt.title('Sales Quantity by Product Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numerical features\n",
    "numerical_cols = ['Customer_Age','Sales_Quantity','Unit_Price','Discount','Total_Sales','Advertising_Spend','Cost_per_unit','Profit','Profit_Margin']\n",
    "plt.figure(figsize=(10,8))\n",
    "correlation_matrix = data[numerical_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ade85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare data for regression\n",
    "X = data.drop(['Total_Sales', 'Date', 'Profit', 'Profit_Margin'], axis=1)\n",
    "y = data['Total_Sales']\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X.select_dtypes(include=['int64','float64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Preprocess: One-hot encode categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build pipeline\n",
    "reg_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = reg_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Regression RMSE: {rmse:.2f}\")\n",
    "print(f\"Regression R^2 Score: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5853f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create binary target: 1 if Sales_Quantity above median, else 0\n",
    "median_sales_qty = data['Sales_Quantity'].median()\n",
    "data['High_Sales'] = (data['Sales_Quantity'] > median_sales_qty).astype(int)\n",
    "\n",
    "X_cls = data.drop(['High_Sales','Total_Sales','Date','Profit','Profit_Margin'], axis=1)\n",
    "y_cls = data['High_Sales']\n",
    "\n",
    "numeric_features_cls = X_cls.select_dtypes(include=['int64','float64']).columns\n",
    "categorical_features_cls = X_cls.select_dtypes(include=['object']).columns\n",
    "\n",
    "preprocessor_cls = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features_cls),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_cls)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cls_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_cls),\n",
    "    ('model', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Train-test split\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(X_cls, y_cls, test_size=0.2, random_state=42)\n",
    "\n",
    "cls_model.fit(X_train_cls, y_train_cls)\n",
    "\n",
    "# Predict\n",
    "y_pred_cls = cls_model.predict(X_test_cls)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test_cls, y_pred_cls)\n",
    "report = classification_report(y_test_cls, y_pred_cls, target_names=['Low Sales','High Sales'])\n",
    "\n",
    "print(f\"Classification Accuracy: {accuracy:.2f}\n",
    "\")\n",
    "print(\"Classification Report:\n",
    "\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a089c266",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "In this notebook, we explored a synthetic sales dataset representing transactions across products, regions, and customer demographics. Exploratory analysis revealed distributions and relationships among features, while correlation analysis highlighted associations between numeric variables. We built a linear regression model to predict Total Sales and achieved a moderate coefficient of determination (RÂ²) and reasonable RMSE. We also constructed a logistic regression classifier to predict whether sales quantity is above the median, evaluating its performance via accuracy and classification report.\n",
    "\n",
    "Future improvements could include testing additional models (e.g., RandomForest or Gradient Boosting), tuning hyperparameters, and incorporating additional derived features or time-series components. This project serves as a starting point for showcasing data analysis and modeling skills for business and data analyst roles.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
